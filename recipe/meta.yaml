{% set name = "openllm" %}
{% set version = "0.4.44" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/openllm-{{ version }}.tar.gz
  sha256: b1063f19a41479464102222b31ef240bf1a6c9557c8e0cfa24959b2c4c10bb34

build:
  skip: true  # [win or osx]
  skip: true  # [py<38]
  entry_points:
    - openllm = openllm_cli.entrypoint:cli
    - openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli
    - openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli
    - openllm-get-prompt = openllm_cli.extension.get_prompt:cli
    - openllm-list-bentos = openllm_cli.extension.list_bentos:cli
    - openllm-list-models = openllm_cli.extension.list_models:cli
    - openllm-playground = openllm_cli.extension.playground:cli
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 1

requirements:
  host:
    - python
    - hatchling ==1.18.0
    - hatch-vcs ==0.3.0
    - hatch-fancy-pypi-readme ==23.1.0
    - pip
  run:
    - python
    - bentoml >=1.1.11,<1.2
    - transformers >=4.36.0
    - openllm-client >={{ version }}
    - openllm-core >={{ version }}
    - safetensors
    - optimum >=1.12.0
    - accelerate
    - ghapi
    - einops
    - sentencepiece
    - scipy
    - python-build <1
    - click >=8.1.3
    - cuda-python
    - bitsandbytes <0.42

test:
  imports:
    - openllm
  commands:
    - pip check
    - openllm --help
    - openllm-dive-bentos --help
    - openllm-get-containerfile --help
    - openllm-get-prompt --help
    - openllm-list-bentos --help
    - openllm-list-models --help
  requires:
    - pip

about:
  summary: 'OpenLLM: Operating LLMs in production'
  home: https://github.com/bentoml/OpenLLM
  license: Apache-2.0
  license_file: LICENSE.md

extra:
  recipe-maintainers:
    - rxm7706
    - conda-forge/openllm-client
    - conda-forge/openllm-core
